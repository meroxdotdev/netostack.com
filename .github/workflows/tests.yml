name: ðŸ§ª Run Tests

on:
  pull_request:
  push:
    branches: [main]

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  id-token: write  # For OIDC with Codecov
  checks: write    # For test reporting

jobs:
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    env:
      NODE_OPTIONS: "--max_old_space_size=8192"

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 22
          cache: npm
      - run: npm ci

      - name: Run unit tests
        id: test
        run: |
          npx vitest run \
            --reporter=github-actions \
            --reporter=verbose \
            --reporter=junit \
            --outputFile=test-results.xml
        continue-on-error: true

      - name: Save test result
        if: always()
        run: echo "${{ steps.test.outcome }}" > test-result-unit.txt

      - name: Upload test result
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-result-unit
          path: test-result-unit.txt

      - name: Upload coverage to Codecov
        if: github.event_name == 'push' || github.event.pull_request.head.repo.full_name == github.repository
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage/lcov.info
          flags: unittests
          name: ip-calc
          fail_ci_if_error: false
        continue-on-error: true

      - name: Unit Test Report
        uses: dorny/test-reporter@v1
        if: always()
        with:
          name: Unit Tests
          path: test-results.xml
          reporter: java-junit
          fail-on-error: false

      - name: Upload coverage artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage
          path: coverage

      - name: Fail if tests failed
        if: steps.test.outcome == 'failure'
        run: exit 1

  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    env:
      NODE_OPTIONS: "--max_old_space_size=8192"

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 22
          cache: npm
      - run: npm ci

      - name: Get Playwright version
        id: playwright-version
        run: echo "version=$(npx playwright --version | awk '{print $2}')" >> $GITHUB_OUTPUT

      - uses: actions/cache@v4
        id: playwright-cache
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-${{ steps.playwright-version.outputs.version }}-chromium-firefox-${{ hashFiles('**/package-lock.json') }}

      - name: Install Playwright
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: npx playwright install --with-deps chromium firefox

      - name: Install Playwright deps only
        if: steps.playwright-cache.outputs.cache-hit == 'true'
        run: npx playwright install-deps chromium firefox

      - name: Run e2e tests
        id: test
        run:  npx playwright test
        continue-on-error: true

      - name: Save test result
        if: always()
        run: echo "${{ steps.test.outcome }}" > test-result-e2e.txt

      - name: Upload test result
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-result-e2e
          path: test-result-e2e.txt

      - name: E2E Test Report
        uses: dorny/test-reporter@v1
        if: always()
        with:
          name: E2E Tests
          path: e2e-results.xml
          reporter: java-junit
          fail-on-error: false

      - name: Upload e2e artifacts
        if: always() && steps.test.outcome != 'success'
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: |
            playwright-report
            test-results

      - name: Fail if tests failed
        if: steps.test.outcome == 'failure'
        run: exit 1

  summary:
    name: Summary
    runs-on: ubuntu-latest
    if: always()
    needs: [unit-tests, e2e-tests]
    steps:
      - name: Download test results
        uses: actions/download-artifact@v4
        with:
          pattern: test-result-*
          merge-multiple: true

      - name: Get test reports
        id: reports
        run: |
          # Get the test report URLs from the Check API
          # Note: This is a simplified approach - in practice you'd use GitHub API
          echo "Getting test report details..."

      - name: Write summary
        env:
          UNIT_JOB: ${{ needs.unit-tests.result }}
          E2E_JOB: ${{ needs.e2e-tests.result }}
        run: |
          # Read actual test results from artifacts (or use job result as fallback)
          UNIT=$(cat test-result-unit.txt 2>/dev/null || echo "$UNIT_JOB")
          E2E=$(cat test-result-e2e.txt 2>/dev/null || echo "$E2E_JOB")

          em() { case "$1" in success) echo "âœ…";; failure) echo "âŒ";; cancelled|skipped) echo "â­ï¸";; *) echo "â”";; esac; }
          line() { r="$1"; n="$2"; cmd="$3"; s="Passing"; [ "$r" = "failure" ] && s="**Failing** - run \`$cmd\`"; [ "$r" = "skipped" ] && s="Skipped"; echo "- $(em "$r") $n: $s"; }

          # Count failures
          failures=0
          [ "$UNIT" = "failure" ] && failures=$((failures + 1))
          [ "$E2E" = "failure" ] && failures=$((failures + 1))

          {
            echo "## ðŸ§ª Test Results"
            echo ""
            line "$UNIT" "Unit Tests" "npm run test:coverage"
            line "$E2E" "E2E Tests" "npm run test:e2e"

            if [ "$failures" -eq 0 ]; then
              echo -e "\nðŸŽ‰ **All test suites passed!**"
              [ "$UNIT" = "success" ] && echo "ðŸ“ˆ Coverage report may be available in [Codecov](https://codecov.io)"
            else
              echo -e "\nâš ï¸ **$failures test suite(s) failed**"
              echo "ðŸ“Š Check the detailed test reports below for more information"
            fi

            echo ""
            echo "---"
            echo ""
            echo "### ðŸ“‹ Detailed Test Reports"
            echo ""
            echo "The test reports below are generated by [dorny/test-reporter](https://github.com/dorny/test-reporter) and show detailed results for each test suite:"
            echo ""
            echo "- **Unit Tests**: Individual test results with execution times and failure details"
            echo "- **E2E Tests**: Browser-based test results across Chromium and Firefox"
            echo ""
            echo "> ðŸ’¡ **Tip**: Click on any failed test in the Checks tab to see detailed error information and stack traces."

          } >> "$GITHUB_STEP_SUMMARY"
